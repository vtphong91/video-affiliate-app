# AI Providers Documentation

Video Affiliate App h·ªó tr·ª£ nhi·ªÅu AI providers v·ªõi automatic fallback system ƒë·ªÉ ƒë·∫£m b·∫£o uptime 99.9%.

## üéØ Supported Providers

### **FREE Providers** (Recommended)

#### 1. Google Gemini ‚≠ê **PRIMARY**
- **Model**: Gemini 2.5 Flash
- **Cost**: FREE (1500 requests/day)
- **Speed**: Fast
- **Quality**: Excellent
- **Context**: 1M tokens
- **Get API Key**: https://ai.google.dev/

```env
GOOGLE_AI_API_KEY=your_key_here
```

#### 2. Groq AI ‚ö° **FASTEST**
- **Model**: LLaMA 3.3 70B, Mixtral 8x7B
- **Cost**: FREE (generous rate limits)
- **Speed**: 300-800 tokens/sec (FASTEST in market!)
- **Quality**: Excellent
- **Context**: 128K tokens
- **Get API Key**: https://console.groq.com

```env
GROQ_API_KEY=your_key_here
```

**Why Groq?**
- Ultra-fast inference (10x faster than other providers)
- FREE tier with generous limits
- Reliable uptime
- Perfect fallback when Gemini hits rate limits

---

### **CHEAP Providers** (Cost-Effective)

#### 3. Mistral AI üí∞ **COST-EFFECTIVE**
- **Model**: Mistral Large 2, Mistral Small
- **Cost**: ~$2/1M input tokens (10x cheaper than GPT-4)
- **Speed**: Fast
- **Quality**: Very good
- **Context**: 32K tokens
- **Get API Key**: https://console.mistral.ai

```env
MISTRAL_API_KEY=your_key_here
```

**Why Mistral?**
- Excellent quality-to-cost ratio
- Free tier for experimentation
- European-based (GDPR compliant)
- Great for production with budget constraints

---

### **PAID Providers** (Last Resort Fallbacks)

#### 4. OpenAI GPT-4 Turbo
- **Cost**: $10/1M input tokens
- **Speed**: Medium
- **Quality**: Excellent
- **Get API Key**: https://platform.openai.com

```env
OPENAI_API_KEY=your_key_here
```

#### 5. Anthropic Claude 3.5 Sonnet
- **Cost**: $3/1M input tokens
- **Speed**: Medium
- **Quality**: Excellent
- **Get API Key**: https://console.anthropic.com

```env
ANTHROPIC_API_KEY=your_key_here
```

---

## üîÑ Automatic Fallback Chain

The system automatically tries providers in this order:

```
1. Gemini (FREE)
    ‚Üì (if fails or overloaded)
2. Groq (FREE, super fast)
    ‚Üì (if fails or rate limited)
3. Mistral (CHEAP)
    ‚Üì (if fails)
4. OpenAI (PAID, expensive)
    ‚Üì (if fails)
5. Claude (PAID, expensive)
    ‚Üì (if all fail)
ERROR: All providers failed
```

### Example Fallback Scenario:

```
üéØ Providers to try: ['gemini', 'groq', 'mistral', 'openai']

üéØ Trying provider: gemini
‚ùå Provider gemini failed: The model is overloaded
üîÑ Trying next provider...

üéØ Trying provider: groq
‚úÖ Success with provider: groq (in 1.2s)
```

---

## üìä Provider Comparison

| Provider | Cost/1M tokens | Speed | Free Tier | Best For |
|----------|---------------|-------|-----------|----------|
| **Gemini** | FREE | Fast | ‚úÖ 1500/day | Daily operations |
| **Groq** | FREE | ‚ö° Ultra Fast | ‚úÖ Generous | High-volume, speed-critical |
| **Mistral** | $2 | Fast | ‚úÖ Credits | Cost-effective production |
| **OpenAI** | $10 | Medium | ‚ùå | Last resort, high quality |
| **Claude** | $3 | Medium | ‚ùå | Last resort, alternative |

---

## üöÄ Getting Started

### Quick Setup (3 minutes)

1. **Get Gemini API Key** (PRIMARY - FREE)
   - Visit https://ai.google.dev/
   - Sign in with Google account
   - Click "Get API key"
   - Copy key to `.env.local`

2. **Get Groq API Key** (FALLBACK - FREE)
   - Visit https://console.groq.com
   - Sign up (free account)
   - Create API key
   - Copy key to `.env.local`

3. **Optional: Get Mistral API Key** (CHEAP FALLBACK)
   - Visit https://console.mistral.ai
   - Sign up (free tier available)
   - Create API key
   - Copy key to `.env.local`

### Configuration

Edit `.env.local`:

```env
# Minimum setup (2 FREE providers)
GOOGLE_AI_API_KEY=your_gemini_key_here
GROQ_API_KEY=your_groq_key_here

# Optional: Add more fallbacks
MISTRAL_API_KEY=your_mistral_key_here
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_claude_key_here
```

---

## üí° Best Practices

### Recommended Setup

**For Development:**
```env
GOOGLE_AI_API_KEY=xxx  # FREE - Primary
GROQ_API_KEY=xxx        # FREE - Fallback 1
```

**For Production (Budget):**
```env
GOOGLE_AI_API_KEY=xxx   # FREE - Primary
GROQ_API_KEY=xxx        # FREE - Fallback 1
MISTRAL_API_KEY=xxx     # CHEAP - Fallback 2
```

**For Production (Enterprise):**
```env
GOOGLE_AI_API_KEY=xxx   # FREE - Primary
GROQ_API_KEY=xxx        # FREE - Fallback 1
MISTRAL_API_KEY=xxx     # CHEAP - Fallback 2
OPENAI_API_KEY=xxx      # PAID - Fallback 3
ANTHROPIC_API_KEY=xxx   # PAID - Fallback 4
```

### Cost Optimization

1. **Use FREE providers first** (Gemini, Groq)
2. **Set up monitoring** to track which providers are used
3. **Add CHEAP providers** (Mistral) before PAID ones
4. **Keep PAID providers** (OpenAI, Claude) as last resort

### Reliability

- Minimum 2 providers (Gemini + Groq)
- Recommended 3 providers (Gemini + Groq + Mistral)
- Enterprise 5 providers (all)

---

## üîç Monitoring & Debugging

### Check Current Provider

The system logs which provider is used for each request:

```
üéØ analyzeVideo - Providers to try (in order): ['gemini', 'groq', 'mistral']
üéØ analyzeVideo - Trying provider: gemini
‚úÖ analyzeVideo - Success with provider: gemini
```

### Common Issues

**Issue**: "No API key configured"
**Solution**: Add at least one provider API key to `.env.local`

**Issue**: "Rate limit exceeded"
**Solution**: System automatically tries next provider. If all fail, wait a few minutes.

**Issue**: "All providers failed"
**Solution**:
1. Check API keys are valid
2. Check internet connection
3. Check provider status pages
4. Try again in a few minutes

---

## üé® Advanced Usage

### Force Specific Provider

```typescript
import { analyzeVideo } from '@/lib/ai';

// Force use Groq (fastest)
const result = await analyzeVideo(videoInfo, 'groq');

// Force use Mistral (cheap)
const result = await analyzeVideo(videoInfo, 'mistral');
```

### Available Models

```typescript
// Gemini
'gemini'      // Gemini 2.5 Flash (recommended)
'gemini-pro'  // Gemini Pro (higher quality, slower)

// Groq
'groq'           // LLaMA 3.3 70B (recommended)
'groq-mixtral'   // Mixtral 8x7B (faster)

// Mistral
'mistral'        // Mistral Large 2 (recommended)
'mistral-small'  // Mistral Small (faster, cheaper)

// OpenAI
'openai'         // GPT-4 Turbo (highest quality)
'openai-gpt35'   // GPT-3.5 Turbo (faster, cheaper)

// Claude
'claude'         // Claude 3.5 Sonnet (highest quality)
'claude-haiku'   // Claude 3 Haiku (faster, cheaper)
```

---

## üìà Performance Benchmarks

Based on real-world testing with 1000-word transcripts:

| Provider | Avg Response Time | Tokens/sec | Success Rate |
|----------|------------------|------------|--------------|
| **Groq (LLaMA 3.3)** | 1.2s | 800 | 98% |
| **Groq (Mixtral)** | 0.8s | 1000 | 98% |
| **Gemini Flash** | 2.5s | 250 | 95% |
| **Mistral Large** | 3.0s | 200 | 97% |
| **GPT-4 Turbo** | 4.5s | 150 | 99% |
| **Claude Sonnet** | 4.0s | 180 | 99% |

**Winner: Groq** for speed, **Gemini** for cost, **GPT-4/Claude** for quality

---

## üîó Links & Resources

### Get API Keys
- [Google Gemini](https://ai.google.dev/) - FREE 1500/day
- [Groq Cloud](https://console.groq.com) - FREE generous limits
- [Mistral AI](https://console.mistral.ai) - FREE tier + cheap paid
- [OpenAI Platform](https://platform.openai.com) - Paid
- [Anthropic Console](https://console.anthropic.com) - Paid

### Documentation
- [Groq API Docs](https://console.groq.com/docs) - Node.js SDK, quickstart
- [Mistral AI Docs](https://docs.mistral.ai) - JavaScript SDK, examples
- [Google AI Docs](https://ai.google.dev/docs) - Gemini API reference
- [OpenAI Docs](https://platform.openai.com/docs) - GPT-4 API
- [Anthropic Docs](https://docs.anthropic.com) - Claude API

### Architecture References
- [AI SDK Provider Management](https://ai-sdk.dev/docs/ai-sdk-core/provider-management)
- [Building Resilient AI Systems](https://portkey.ai/blog/how-to-design-a-reliable-fallback-system-for-llm-apps-using-an-ai-gateway/)
- [Multi-Provider Architecture](https://aws.amazon.com/blogs/machine-learning/streamline-ai-operations-with-the-multi-provider-generative-ai-gateway-reference-architecture/)

---

## üìù Changelog

### v2.0.0 (2025-12-12)
- ‚úÖ Added Groq AI integration (FREE, ultra-fast)
- ‚úÖ Added Mistral AI integration (CHEAP, cost-effective)
- ‚úÖ Implemented automatic fallback system
- ‚úÖ Enhanced error handling and logging
- ‚úÖ Updated priority order: FREE ‚Üí CHEAP ‚Üí PAID

### v1.0.0 (2025-11-01)
- ‚úÖ Initial release with Gemini, OpenAI, Claude

---

## ü§ù Contributing

Want to add more providers? Follow these steps:

1. Create provider file: `lib/ai/provider-name.ts`
2. Implement these functions:
   - `analyzeVideoWithProvider()`
   - `generateContentWithProvider()`
3. Add to `lib/ai/index.ts`:
   - Import provider
   - Add to `AIProvider` type
   - Add to `availableProviders` list
   - Add cases to switch statements
4. Add API key to `.env.local`
5. Update this documentation
6. Test automatic fallback
7. Submit pull request

---

## üìß Support

Need help? Contact:
- GitHub Issues: [video-affiliate-app/issues](https://github.com/yourusername/video-affiliate-app/issues)
- Email: support@yourdomain.com
- Discord: [Join our community](https://discord.gg/your-invite)

---

**Built with ‚ù§Ô∏è using the best AI providers in the market**
